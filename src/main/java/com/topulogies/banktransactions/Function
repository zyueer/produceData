容错策略+多数据源获取数据
场景：处理银行业务
需求：1、如果事务失败了，重新发送消息 2、如果失败了太多次，终结拓扑运行
需求详述：创建一个 spout 和一个 bolt，spout 随机发送100个事务 ID，有80%的元组不会被 bolt 收到。
        实现 spout 时利用 Map 分发事务消息元组，这样就比较容易实现重发消息。
        如果有未发送的消息，得到每条事务消息和它的关联 ID，把它们作为一个元组发送出去，最后清空消息队列。
        值得一提的是，调用 map 的 clear 是安全的，因为 nextTuple 失败时，只有 ack 方法会修改 map，而它们都运行
        在一个线程内。

        维护两个 map 用来跟踪待发送的事务消息和每个事务的失败次数。ack 方法只是简单的把事务从每个列表中删除
分析：fail 方法决定应该重新发送一条消息，还是已经失败太多次而放弃它。

如何从多数据源获取数据？
1、直接连接
    在一个直接连接的架构中，spout 直接与一个消息分发器连接。
2、消息队列   Redis  Kafka
  第二种方法是，通过一个队列系统接收来自消息分发器的消息，并把消息转发给 spout。更进一步的做法是，
  把队列系统作为 spout 和数据源之间的中间件，在许多情况下，你可以利用多队列系统的重播能力增强队列可靠性。